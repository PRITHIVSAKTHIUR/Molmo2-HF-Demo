{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Molmo2-HF-Demo**\n",
        "A Gradio-based demonstration for the AllenAI Molmo2-8B multimodal model, enabling image QA, multi-image pointing, video QA, and temporal tracking. Users upload images or videos, provide natural language prompts (e.g., \"Point to the boats\" or \"Track the player\"), and receive generated responses with visual annotations: red circles and labels for detected points on images/videos. Supports multi-image galleries and MP4 videos with frame sampling.\n"
      ],
      "metadata": {
        "id": "jUscAcvo4rQR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Brwj01Bk4hsf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PRITHIVSAKTHIUR/Molmo2-HF-Demo.git\n",
        "%cd Molmo2-HF-Demo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r pre-requirements.txt"
      ],
      "metadata": {
        "id": "kuBcyv2W45f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "E5pQPzpc49F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "id": "aVhhvCRo5AqP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}